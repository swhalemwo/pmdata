<!-- --- -->
<!-- title: "artfacts" -->
<!-- output: rmarkdown::html_vignette -->
<!-- vignette: > -->
<!--   %\VignetteIndexEntry{example} -->
<!--   %\VignetteEngine{knitr::rmarkdown} -->
<!--   %\VignetteEncoding{UTF-8} -->
<!-- --- -->

```{r, include = FALSE, cache=TRUE}
knitr::opts_chunk$set(
                      collapse = TRUE,
                      comment = "#>"
)
```

<!-- ## cache = FALSE, -->

```{r setup,  echo = F, results = F, message = F}
library(pmdata)
library(data.table)
adt <- as.data.table
library(ggplot2)
library(collapse)
library(jtls)
library(countrycode)
library(purrr)
library(scales, include.only = "rescale")
library(ggrepel)
PMDATA_LOCS <- gc_pmdata_locs()
```


##  Merging Artfacts to PMDB

<!-- First we generate a bunch of objects that will help us later:  -->

```{r datat_prep, echo = F, cache=TRUE}
## get af exhibitions and institutions
dt_af_exhbs <- gd_af_exhbs()
dt_af_instns <- gd_af_instns()
dt_af_links_exhb_ppl <- gd_af_links_exhb_ppl()
dt_af_people <- gd_af_people()

## get PMDB
dt_pmdb <- suppressWarnings(gd_pmdb(gd_pmdb_excl(only_pms = F), verbose = NULL)) %>%    
    .[museum_status %in% c("private museum", "closed")]

## import match file
dt_matches_pmdb_af <- gd_af_pmdb_matches()

## compare coverage: 
dt_pmdb_af <- join(dt_matches_pmdb_af, dt_pmdb[, .(ID, name, iso3c, museum_status)],
                   on = c(PMDB_ID = "ID"), how = "inner", verbose = F)

```

Overall coverage (private museums in our database which are in our sample of the Artfacts database) is `r dt_pmdb_af[, 100*sum(AF_IID != "nomatch")/.N]`%. Differences by museum status exist, but are not very large: `r dt_pmdb_af[museum_status =="private museum", 100*sum(AF_IID != "nomatch")/.N]`% for open, `r dt_pmdb_af[museum_status =="closed", 100*sum(AF_IID != "nomatch")/.N]`% for closed.


<!-- ```{r af_cvrg, echo = F} -->
<!-- ## .[grepl("carmignac", name, ignore.case = T)] -->
<!-- dt_pmdb_af[, .N, .(museum_status, af_cvrg = fifelse(AF_IID != "nomatch", "AF_IID", "noAF_IID"))] %>% -->
<!--     .[, prop := N/sum(N), museum_status] %>% -->
<!--     .[, cell_fmtd :=sprintf("%s (%s %%)", N, format(100*prop, digits =2, nsmall = 2 ,))] %>% -->
<!--     dcast(af_cvrg ~ museum_status, value.var = "cell_fmtd") -->
    
<!-- ``` -->



```{r, echo = F, cache=TRUE}
## calculate AF coverage by country and museum status
dt_pmdb_af_cvrgvis <- dt_pmdb_af[, .N, .(museum_status, iso3c, AF_IID != "nomatch")] %>%
    ## expand DT by all possible combinations
    .[CJ(AF_IID, iso3c, museum_status, unique = T), on = .(iso3c, AF_IID, museum_status)] %>%
    replace_NA(value = 0) %>%  # make values of combination not covered in the data 0
    .[, N_cry_ms := sum(N), .(museum_status, iso3c)] %>% # count per country and museum status (ms)
    .[, prop_covered := N/N_cry_ms] %>% # prop with AF_IID (by country and museum_status)
    .[AF_IID == TRUE] %>% # only focus on covered percentages (not covered is 1- covered)
    .[, museum_status := factor(museum_status, levels = c("private museum", "closed"))] %>% 
    .[order(museum_status, prop_covered)] %>%  # reorder in for ggplot
    .[, iso3c := factor(iso3c, funique(iso3c))] %>%
    .[, reg6 := rcd_iso3c_reg6(iso3c)] %>%
    .[!is.nan(prop_covered)] # %>% .[iso3c == "DEU"]
```

Coverage by region: 

```{r, fig.dim = c(8, 8), echo = F, cache=TRUE}
## coverage by  region
dt_pmdb_af %>% copy() %>% 
    .[, reg_sub := countrycode(iso3c, "iso3c", "un.regionsub.name",
                               custom_match = c(TWN = "South-eastern Asia"))] %>%
    .[, reg6 := rcd_iso3c_reg6(iso3c)] %>% 
    .[, .N, .(museum_status, reg_sub, reg6, AF_IID != "nomatch")] %>%
    .[, prop_covered := N/sum(N), .(museum_status, reg_sub, reg6)] %>% 
    .[AF_IID == TRUE] %>%
    .[, museum_status := factor(museum_status, levels = c("private museum", "closed"))] %>%
    .[order(museum_status, prop_covered)] %>% .[, reg_sub := factor(reg_sub, funique(reg_sub))] %>% 
    ggplot(aes(x=prop_covered, y=reg_sub, group = museum_status, color = museum_status, fill = museum_status)) +
    geom_col(position = position_dodge2(preserve = "single")) +
    ## geom_point() + 
    facet_grid(reg6 ~ ., scales = "free", space = "free")
```

Europe seems to be covered best, Souther Asia worst (not all regions have museums which have closed, which is why not all bars are present). 


Coverage also differs by country: 


```{r,  fig.dim = c(8,9),  echo = F, cache=TRUE}
dt_pmdb_af_cvrgvis %>% 
    ggplot(aes(x = prop_covered, y = iso3c, color = museum_status, group = museum_status, size = N_cry_ms)) +
    geom_point(position = position_dodge(width = 0.8)) +
    geom_text(mapping = aes(label = N_cry_ms),
              position = position_dodge(width = 0.8),
              color = "black",
              ## manually scale font size to make it fit in the bubbles
              size = dt_pmdb_af_cvrgvis[order(reg6), rescale(N_cry_ms, to = c(2, 4))]) + 
    facet_grid(reg6 ~ ., scales = "free_y", space = "free_y") +
    scale_size_continuous(range = c(2,6))
``` 


European countries seem to be covered best (e.g. almost three quarters of Germany's 60 open museums are covered, compared to lesss than half of South Korea's 50).  

Closed museums are also not covered well in Asia, e.g. none of the closed museums in 7 Asian countries are included, compared to only 1 European country and 1 African. 

<!-- Alternative way of plotting country coverage, but doesn't look so good:  -->

<!-- ```{r, fig.dim = c(10,8), echo = F} -->
<!-- ##  -->
<!-- dt_pmdb_af_cvrgvis %>% copy() %>% -->
<!--     .[, museum_status_short := fifelse(museum_status == "closed", "CL", "OP")] %>% -->
<!--     .[, lbl := sprintf("%s -  %s", iso3c, museum_status_short)] %>%  -->
<!--     ggplot(aes(x=N_cry_ms, y = prop_covered, color = museum_status, label = iso3c)) + -->
<!--     geom_point() + -->
<!--     geom_text_repel(box.padding = 0.1, force_pull = 0) -->

<!-- ``` -->

## Artfacts coverage over time 

```{r, echo = F, cache=TRUE}
## merge AF exhibitions to PMDB
dt_pmdb_exhbs <- join(dt_af_exhbs,
     dt_pmdb_af[AF_IID != "nomatch", .(InstitutionID = as.integer(AF_IID), PMDB_ID, name)], 
     on = "InstitutionID", how = 'inner', verbose = 0) %>%
    .[, begin_year := year(BeginDate)]

dt_af_exhbs_pmdb <- join(dt_af_exhbs,
                         dt_pmdb_af[AF_IID != "nomatch", .(InstitutionID = as.integer(AF_IID), PMDB_ID, name)],
                         on = "InstitutionID", how = 'left', verbose = 0) %>%
    .[, begin_year := year(BeginDate)]
```


Around `r format(100*(fnrow(dt_pmdb_exhbs)/fnrow(dt_af_exhbs)), digits = 2, nsmall = 2)` % of exhibitions in Artfacts are in private museums. 


percentage of shows in private museums over time: increases quite over time

```{r, fig.dim = c(8, 6), echo = F, cache=TRUE}
dt_af_exhbs_pmdb[, .(prop_pmdb = sum(100*!is.na(PMDB_ID))/.N), begin_year] %>%
    .[begin_year %between% c(1990, 2023)] %>% 
    ggplot(aes(x=begin_year, y = prop_pmdb)) + geom_line()
```

distribution of types of institutions and exhibitions


```{r, echo = F, cache=TRUE}
## get exhibition data with institution info (w, i, info)
dt_af_exhbs_wiinfo <- join(dt_af_exhbs, dt_af_instns, on = c(InstitutionID = "ID"), verbose = F) %>%
    .[, begin_year := year(BeginDate)]

dt_af_t_itype <- dt_af_exhbs_wiinfo[, .(nbr_type = fnunique(InstitutionID), nbr_exhbs = .N), InstitutionType] %>%
    .[, `:=`(perc_type = 100*nbr_type/sum(nbr_type), perc_exhbs = 100*nbr_exhbs/sum(nbr_exhbs))] %>%
    .[order(-nbr_exhbs)]
```

```{r, cache=TRUE}
dt_af_t_itype %>% print(n=25, row.names = F, width = 60)
```
Most exhibitions are in Galleries, Public Instititutions and NPOs.

type over time: 

```{r, fig.dim = c(9,6), echo = F, cache=TRUE}

rbind(
    dt_af_exhbs_wiinfo[, .N, .(InstitutionType, begin_year)] %>%
    .[begin_year %between% c(1990, 2022)] %>%
    .[, .SD[any(N > 150)], InstitutionType] %>% # only types which at least once gets 150 exhbs per year
    .[order(-N)] %>% .[, InstitutionType := factor(InstitutionType, levels = funique(InstitutionType))] %>%
    .[, src := "type"],
    dt_af_exhbs_wiinfo %>% # aggregate total 
    .[begin_year %between% c(1990, 2022)] %>%
    .[, .N, begin_year] %>% .[, `:=`(src = "total", InstitutionType = "all")]) %>% 
    ggplot(aes(x=begin_year, y=N, color = InstitutionType)) + geom_line()
```

huh some decrease by more than 50% from ~2012 onwards? 

could be that coverage changes over time by: 

- country: some countries get covered less

- artist: some artists get covered less -> exhibition numbers of active artists can stay stable/go up even when total number decreases

- institution: some institutions get covered less: average exhibition numbers of active institutions can be stable/go up even when total number decreases



```{r, fig.dim = c(9, 8), echo = F, cache=TRUE}
## artfacts exhb with people info 
dt_af_exhbs_wpinfo <- join(dt_af_links_exhb_ppl, dt_af_exhbs_wiinfo, on = c(ExhibitionID = "ID"), verbose = 0)
```




by country: 

```{r, fig.dim = c(12, 8), echo = F, cache=TRUE}
## count over time by institution type and country 
dt_af_exhbs_wiinfo[, .N, .(InstitutionType, begin_year, CountryName)] %>%
    .[begin_year %between% c(1990, 2022)] %>%
    .[, .SD[any(N > 75)], .(InstitutionType, CountryName)] %>%
    .[order(-N)] %>% .[, CountryName := factor(CountryName, levels = funique(CountryName))] %>% 
    ggplot(aes(x=begin_year, y = N, color = InstitutionType)) +
    geom_line() +
    facet_wrap(~ CountryName, scales = "free_y") +
    theme(strip.text = element_text(margin = margin(0,0,0,0, "cm")),
          legend.position = "bottom",
          axis.text.x = element_text(angle = 20))
          
```

pretty much in all countries, both big and small (ordered by max size)  


is that decrease a within-institution effect? or "closures", i.e. exclusion? -> look at average numbers

```{r, fig.dim = c(10, 6), echo = F, cache=TRUE}
rbind(
    ## average number of exhibitions by InstitutionType
    dt_af_exhbs_wiinfo[, .N, .(InstitutionType, begin_year, InstitutionID)] %>%
    .[begin_year %between% c(1990, 2022), .SD[any(sum(N) > 2000)], .(InstitutionType)] %>%
    .[, .(vlu = mean(N), measure = "instn_avg_exhbcnt"), .(InstitutionType, begin_year)],
    ## number of unique Institutions per type and year
    dt_af_exhbs_wiinfo[, .(vlu = fnunique(InstitutionID), measure = "instn_unq_cnt"),
                       .(InstitutionType, begin_year)] %>%
    .[begin_year %between% c(1990, 2022), .SD[any(sum(vlu) > 2000)], .(InstitutionType)],
    ## average number of exhibitions for an artist in institution type per year
    dt_af_exhbs_wpinfo[, .N, .(PeopleID, begin_year, InstitutionType)] %>%
    .[begin_year %between% c(1990, 2022), .SD[any(sum(N) > 10000)], .(InstitutionType)] %>%
    .[, .(vlu = mean(N), measure = "artist_avg_exhbcnt"), .(begin_year, InstitutionType)],
    ## Artist data
    dt_af_exhbs_wpinfo[begin_year %between% c(1990, 2022)] %>%
    .[, .(artist_unq_cnt = fnunique(PeopleID), artist_ttl_cnt = .N), .(InstitutionType, begin_year)] %>%
    .[, .SD[any(artist_unq_cnt > 500)], InstitutionType] %>% 
    melt(id.vars = c("InstitutionType", "begin_year"), variable.name = "measure", value.name = "vlu")) %>%
    ## categorize some more
    .[, `:=`(entity = factor(fifelse(grepl("^instn", measure), "instn", "artist"), levels = c("instn", "artist")),
             measure2 = gsub("artist_|instn_", "", measure))] %>%
    ggplot(aes(x=begin_year, y=vlu, color = InstitutionType)) +
    geom_line() +
    facet_wrap(entity ~ measure2, scales = "free") +
    theme(legend.position = "bottom")
```

seems to be in all kinds of settings: declines from ~2012 onwards in all: 

- instititutions: 
    - number with at least 1 show (instn, unq_cnt)
    - average number of exhibitions by active institutions (instn, avg_exhbcnt)

- artists: 
    - number of artists exhibited in total (artist, ttl_cnt)
    - number of unique artists exhibited (artist, unq_cnt)
    - average number of exhibitions (artist, avg_exhbcnt)


possible explanations: 

- data collection: 
  Artfacts data collection has become less complete since 2012? but weird that it's so gradual  
  change in availability in their sources?  
  data processing errors on their part?  


- substantial: art field has shrunk since 2012?  
  look at auction data? 

way to deal with it for PM size indicator: 

- rather than count of exhibitions, percent of total exhibitions?  
  this has the funny/undesirable property that it shrinks if exhibition count stays the same, but more museums are added
  
- rank: e.g. which decile  
  same issue: by more other museums doing more, rank can go down
  
<!-- AF: founded in 2001 -->
<!-- https://web.archive.org/web/20240000000000*/artfacts.net: less active in period 2014-2017 -->
<!-- website look same tho -->

## artist descriptives

Could be that decline is due to artists aging?

```{r, echo = F, fig.dim = c(7, 5), cache=TRUE}
dt_af_people[, .N, BirthYear] %>% ggplot(aes(x=BirthYear, y = N)) + geom_col()
```

peak in Birthyear is around 1977, they are in their 30s when exhibition counts decline.. 
could it be that older artists retire? oldest are 67 then 
-> look at average age by year


```{r, echo = F, fig.dim = c(10,7), cache=TRUE}
## with artist info
dt_af_exhbs_wainfo <- join(dt_af_exhbs_wpinfo,
                            setnames(copy(dt_af_people), old = "Name", new = "artist_name"), # add totals
                           on = c(PeopleID = "ID"), verbose = 0)

dt_af_exhbs_wainfo %>%
    .[, .(mean_age = mean(begin_year - BirthYear), N = .N), .(InstitutionType, begin_year)] %>%
    .[begin_year %between% c(1990, 2022), .SD[any(N > 2000)], InstitutionType] %>%
    rbind(., 
          .[, .(mean_age = weighted.mean(mean_age, w = N), InstitutionType = "all",  N = sum(N)), begin_year]) %>% 
    ggplot(aes(x=begin_year, y = mean_age, color = InstitutionType)) + geom_line()
```

huh average age increases A LOT:  
but is kinda plausible: in 1990 there are actually many artists who are born before 1945, and which are missing here  
the lack of them is pulling down the average  
quite interesting that age continues to increase all the way:  
-> even in 2022 there are still substantial amounts of pre-1945 artists around?  
-> artists become older overall  

actually this makes absolute measurement unreliable, even if there was no decline after 2012:  
survival compares based on age (not year): in our subset, number of exhibitions in 1995 is different from that in 2015 at the same size, because in 1995 a larger portion is of pre-1945 artists -> number of exhibitions in 1995 is lower than in 2015 because more are missing (even if museums are otherwise identical)  

also, this makes decline even worse: there should be muuuch more, because the further the time goes, the lower is the proportion of pre-1945 artists which get excluded



could also be that demographics are less complete later on: exhibition data is in AF, but not in our dataset because demographics are incomplete



## museum size indicators 

look at exhibition in PMs a bit more -> can it be used to build size indicator?

total exhibitions counts change substantially over time -> having 3 exhibitions in 2005 has different meaning than in 2012
-> would have to use quantile, rather than absolute count: otherwise I assume 3 in 2005 measure same thing as in 2012

```{r, echo = F, cache = T}
## dt_af_exhbs_pmdb[complete.cases(PMDB_ID, begin_year), .N, .(PMDB_ID, begin_year)]

## calculate deciles
## dt_af_exhbs_pmdb[, .N, .(InstitutionID, CountryName, begin_year)]

## construct institution trajectories: activity as quantile
## include 0 for all the institutions that have no exhibitions in a year, but had at least one before/after
dt_af_qntlprep <- dt_af_exhbs_pmdb[!is.na(begin_year), .(begin_year = min(begin_year):max(begin_year)),
                 .(InstitutionID, PMDB_ID, CountryName)] %>%
    join(dt_af_exhbs_pmdb[, .N, .(InstitutionID, begin_year)], on = c("InstitutionID", "begin_year"),
         verbose = 0) %>%
    replace_NA(cols = "N") # fill up no exhbs with 0
    
## calculate quantile with ecdf (more comfy than quantile())
## https://stats.stackexchange.com/questions/50080/estimate-quantile-of-value-in-a-vector
ecdf_fun <- function(x,perc) ecdf(x)(perc) # get quantile of value


## dt_af_qntlprep[CountryName == "Germany" & begin_year == 2012] %>% copy() %>%
##     .[, quantile := ecdf_fun(N, N)] %>% .[, .(N2 =.N), .(N, quantile)] %>% .[order(N)]

## test with austria data
dt_au <- copy(dt_af_qntlprep)[CountryName == "Austria"] %>%
    ## .[, quantile := ecdf_fun(N, N), .(CountryName, begin_year)]
    .[, quantile := ecdf_fun(N, N), .(begin_year, CountryName)]    

```

all institutions: 
```{r, echo = T, cache = T, echo = F,  fig.dim = c(8,6)}
dt_af_qntlprep[, .(N2 = .N), N] %>% .[order(N2)] %>%
    .[, N := factor(N, levels = N)] %>% 
    ggplot(aes(x = N2, y=factor(N))) + geom_col() + 
    geom_text(mapping = aes(label = N2))


```

visualize quantile rank of PMs over time: 

```{r, echo = F, cache = T, fig.dim = c(8,6)}

dt_qntlyear_viz <- copy(dt_af_qntlprep) %>%
    .[, quantile := ecdf_fun(N, N), .(begin_year)] %>%
    ## focus on countries with largest PMs population
    .[!is.na(PMDB_ID) & begin_year <= 2020, .SD[fnunique(PMDB_ID) > 5], CountryName]

dt_qntlCY_viz <- copy(dt_af_qntlprep) %>%
    .[, quantile := ecdf_fun(N, N), .(CountryName, begin_year)] %>%
    ## focus on countries with largest PMs population
    .[!is.na(PMDB_ID) & begin_year <= 2020, .SD[fnunique(PMDB_ID) > 5], CountryName]

                                        
ggplot(dt_qntlCY_viz, aes(x=begin_year, y=quantile, group = PMDB_ID)) +
    geom_line(alpha = 0.2) +
    facet_wrap(~CountryName)

```

look at difference between different quantile calculation methods:  
- year  
- country-year  

```{r, echo = F, cache = T, fig.dim = c(8,6)}
dt_qntl_cprcalcs <- rbind(copy(dt_qntlyear_viz)[, src := "year"],
      copy(dt_qntlCY_viz)[, src := "CY"]) %>%
    dcast(InstitutionID + PMDB_ID + begin_year + CountryName + N ~ src, value.var = "quantile") %>%
    .[, diff := CY - year] %>%
    .[, diff_cut := cut(diff, breaks = seq(floor(min(diff)*20)/20, ceiling(max(diff)*20)/20, by = 0.05))]

dt_qntl_cprcalcs %>% ggplot(aes(x=diff)) + geom_density() +
    facet_wrap(~CountryName, scales = "free_y") + geom_vline(xintercept = 0, linetype = "dashed")
                                                             

dt_qntl_cprcalcs %>% 
    .[, .N, diff_cut] %>% .[, prop := round(100*N/sum(N), 2)] %>% 
    ggplot(aes(x=diff_cut, y= N, label = prop)) + geom_col() + geom_text(nudge_y = 20)

```

strange: there quite some diff: 32% of PM-years have abs(diff) > 0.05,  
hmm around 7% have abs(diff) > 0.1  
quantile has SD = 0.24 in closing data, and that has a lot of within jankiness -> meaningful between-variation is maybe 0.15? 

maybe also due most PMs being located in handful of countries, which are relatively well covered? 



look only at Austrian PMs: 

```{r, echo = F, cache =T, fig.dim = c(8,6)}



dt_au %>% 
    .[!is.na(PMDB_ID), .SD[fnunique(begin_year) > 1], PMDB_ID] %>% # only PMs that have exhbs in more than 1 year
    ggplot(aes(x=begin_year, y=quantile, color = factor(N), group = PMDB_ID)) + 
    geom_line(show.legend = F) + geom_point() +
    geom_text(mapping = aes(label= N), color = "black") + 
    facet_wrap(~PMDB_ID)

```


plot relation between counts and quantile:

```{r, echo = F, cache = T}

dt_au[begin_year >= 1990, .SD[1], .(begin_year, N)] %>%
    .[N < 15] %>% 
    ggplot(aes(x=begin_year, y=quantile, color = factor(N))) + geom_line() + geom_point()

```

plot relation between counts and quantile: 

```{r, echo = F, cache =T}
## hmm probably easier when defining quantiles manually
copy(dt_af_qntlprep)[CountryName == "Austria", quantile(N, probs = seq(0, 1, 0.1)) %>% as.list, begin_year] %>%
    melt(id.vars = "begin_year", variable.name = "thld", value.name = "vlu") %>%
    .[begin_year >= 1990] %>%
    .[thld != "100%"] %>%  # yeet 100% (is max value -> makes other shrink super much
    ggplot(aes(x=begin_year, y=vlu, color = thld)) + geom_line()
```


hmm a lot of flickering: is variation larger within than between? -> xtsum

why does log(quantile) not work? 

look at within/between variance of quantile score: 
```{r, echo = F, cache = T}

library(jtls)
dt_xtsum <- copy(dt_af_qntlprep) %>% 
    .[, quantile := ecdf_fun(N, N), .(CountryName, begin_year)] %>% 
    xtsum(varname = quantile, unit = InstitutionID)

print(dt_xtsum)


```
only look at within/between variance of quantile score of PMs: 

```{r, echo = F, cache = T}
copy(dt_af_qntlprep) %>% 
    .[, quantile := ecdf_fun(N, N), .(CountryName, begin_year)] %>%
    .[!is.na(PMDB_ID)] %>%
    xtsum(varname = quantile, unit = InstitutionID)
```

hmm around equal within/between variance: hard to say if that's plausible (would expect that more between than within variance), but it's not absurd either.. 



look at within-between variation of newest size measure: exhbqntl_roll (quantile of number of exhibitions in last 5 years):  
FIXME: this is spaghetti code: back-sourcing stuff from closing paper in pmdata is big NONO  

```{r, echo = F, cache = T}
c_dirs <- gc_dirs(dir_proj = "/home/johannes/Dropbox/phd/papers/closing/") ## project dirs
PMDATA_LOCS <- gc_pmdata_locs()
source("/home/johannes/Dropbox/phd/papers/closing/scripts/regression.R")
END_YEAR <- 2021
dt_pmx <- suppressWarnings(gd_pmx(dt_pmdb))

dt_af_size <- suppressWarnings(gd_af_size(dt_pmx))

xtsum(dt_af_size, varname = exhbqntl_roll, unit = PMDB_ID)
```
well exhbqntl_roll has less within variation, which isn't super surprising since it's smoothed out, so it should be lower by definition.. 
